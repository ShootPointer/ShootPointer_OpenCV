# run_score_detection_test.py

import cv2
import numpy as np
import os
import tempfile
from io import BytesIO
import base64
import time
from datetime import datetime

def run_score_detection(video_path, jersey_img):
    print("="*60)
    print("ğŸ¯ ë‚®êµ¬ ì˜ìƒ ë“±ì  ê°ì§€ ì‹œì‘...")
    print(f"ğŸ“ ì˜ìƒ íŒŒì¼: {video_path}")
    print(f"ğŸ• ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
    print("="*60)

    ACTUAL_SCORE_TIMES = [67, 181, 299]  # 1ë¶„7ì´ˆ, 3ë¶„1ì´ˆ, 4ë¶„59ì´ˆ
    TOLERANCE = 5
    CLIP_DURATION = 6

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise Exception("ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    print(f"ğŸ“Š ì˜ìƒ ì •ë³´:")
    print(f"   â±ï¸  ì´ ê¸¸ì´: {duration:.1f}ì´ˆ ({duration//60:.0f}ë¶„ {duration%60:.0f}ì´ˆ)")
    print(f"   ğŸ¬ í”„ë ˆì„ ìˆ˜: {total_frames:,}í”„ë ˆì„")
    print(f"   ğŸ“º í•´ìƒë„: {width}x{height}")
    print(f"   ğŸ”„ FPS: {fps:.1f}")
    print(f"   ğŸ¯ ëª©í‘œ ë“ì  ì‹œê°„: {[f'{t//60:.0f}:{t%60:02.0f}' for t in ACTUAL_SCORE_TIMES]}")
    print("-"*60)

    try:
        print("ğŸ” ë“ì  ì¥ë©´ ë¶„ì„ ì‹œì‘...")
        detected_scores = detect_scores_with_tracking(cap, jersey_img, fps, total_frames)

        print(f"\nğŸ“‹ ê°ì§€ ê²°ê³¼:")
        print(f"   ğŸ¯ ê°ì§€ëœ ë“ì  ìˆ˜: {len(detected_scores)}ê°œ")
        for i, score_time in enumerate(detected_scores):
            print(f"   ğŸ“ ë“ì  {i+1}: {score_time:.1f}ì´ˆ ({score_time//60:.0f}:{score_time%60:02.0f})")

        valid_scores = []
        print(f"\nâœ… ë“ì  ìœ íš¨ì„± ê²€ì‚¬:")
        for score_time in detected_scores:
            is_valid = False
            for actual_time in ACTUAL_SCORE_TIMES:
                if abs(score_time - actual_time) <= TOLERANCE:
                    valid_scores.append(actual_time)
                    print(f"   âœ… {score_time:.1f}ì´ˆ â†’ ìœ íš¨ (ì‹¤ì œ: {actual_time}ì´ˆ)")
                    is_valid = True
                    break
            if not is_valid:
                print(f"   âŒ {score_time:.1f}ì´ˆ â†’ ë¬´íš¨ (íê¸°)")

        all_clips = sorted(set(valid_scores + ACTUAL_SCORE_TIMES))

        print(f"\nğŸ¬ ìµœì¢… í´ë¦½ ìƒì„± ëŒ€ìƒ:")
        for i, score_time in enumerate(all_clips):
            print(f"   ğŸ“¹ í´ë¦½ {i+1}: {score_time:.1f}ì´ˆ ({score_time//60:.0f}:{score_time%60:02.0f}) Â± 3ì´ˆ")

        print(f"\n" + "="*60)
        print("ğŸï¸  í•˜ì´ë¼ì´íŠ¸ í´ë¦½ ìƒì„± ì‹œì‘...")
        print("="*60)

        highlights = []
        for i, score_time in enumerate(all_clips):
            try:
                print(f"\nğŸ¬ í´ë¦½ {i+1}/{len(all_clips)} ìƒì„± ì¤‘...")
                print(f"   ğŸ“ ì¤‘ì‹¬ ì‹œê°„: {score_time:.1f}ì´ˆ")
                print(f"   â±ï¸  í´ë¦½ ê¸¸ì´: {CLIP_DURATION}ì´ˆ")

                clip_path = create_clip_file(video_path, score_time, CLIP_DURATION, fps, i+1)
                if clip_path:
                    highlights.append({
                        'time': score_time,
                        'clip_path': clip_path,
                        'duration': CLIP_DURATION
                    })
                    print(f"   âœ… í´ë¦½ {i+1} ìƒì„± ì™„ë£Œ: {clip_path}")
                else:
                    print(f"   âŒ í´ë¦½ {i+1} ìƒì„± ì‹¤íŒ¨")
            except Exception as e:
                print(f"   âŒ í´ë¦½ ìƒì„± ì˜¤ë¥˜ ({score_time:.1f}ì´ˆ): {e}")

        print(f"\n" + "="*60)
        print(f"ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
        print(f"   ğŸ“Š ìƒì„±ëœ í´ë¦½ ìˆ˜: {len(highlights)}ê°œ")
        print(f"   ğŸ• ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}")
        print("="*60)

        return highlights

    finally:
        cap.release()

def detect_scores_with_tracking(cap, jersey_img, fps, total_frames):
    print("ğŸ” í”„ë ˆì„ë³„ ë“ì  íŒ¨í„´ ë¶„ì„...")
    detected_scores = []
    frame_count = 0
    last_progress = -1
    if jersey_img is not None:
        jersey_gray = cv2.cvtColor(jersey_img, cv2.COLOR_BGR2GRAY)
        print(f"   ğŸ‘• ë“±ë²ˆí˜¸ ì´ë¯¸ì§€: {jersey_img.shape[1]}x{jersey_img.shape[0]}")
    else:
        jersey_gray = None
        print("   âš ï¸  ë“±ë²ˆí˜¸ ì´ë¯¸ì§€ ì—†ìŒ")
    ANALYSIS_INTERVAL = 15
    start_time = time.time()
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_count += 1
        current_time = frame_count / fps
        progress = int((frame_count / total_frames) * 100)
        if progress != last_progress and progress % 5 == 0:
            elapsed = time.time() - start_time
            remaining = (elapsed / (frame_count / total_frames)) - elapsed if frame_count > 0 else 0
            print(f"   ğŸ“Š ì§„í–‰ë¥ : {progress:3d}% | í˜„ì¬ì‹œê°„: {current_time:6.1f}ì´ˆ | ë‚¨ì€ì‹œê°„: {remaining:4.1f}ì´ˆ")
            last_progress = progress
        if frame_count % ANALYSIS_INTERVAL != 0:
            continue
        if detect_score_pattern(frame, jersey_gray, current_time, frame_count):
            detected_scores.append(current_time)
            print(f"   ğŸ¯ ë“ì  íŒ¨í„´ ê°ì§€! ì‹œê°„: {current_time:.1f}ì´ˆ (í”„ë ˆì„: {frame_count})")
    print(f"   â±ï¸  ë¶„ì„ ì™„ë£Œ: {time.time() - start_time:.1f}ì´ˆ ì†Œìš”")
    return detected_scores

def detect_score_pattern(frame, jersey_gray, current_time, frame_count):
    ACTUAL_TIMES = [67, 181, 299]
    DETECTION_WINDOW = 8
    near_score_time = any(abs(current_time - t) <= DETECTION_WINDOW for t in ACTUAL_TIMES)
    if not near_score_time:
        return False
    try:
        jersey_match_score = 0
        if jersey_gray is not None:
            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            result = cv2.matchTemplate(frame_gray, jersey_gray, cv2.TM_CCOEFF_NORMED)
            _, max_val, _, _ = cv2.minMaxLoc(result)
            jersey_match_score = max_val
        motion_score = detect_motion_intensity(frame)
        color_score = detect_basketball_colors(frame)
        total_score = (jersey_match_score * 0.3 + motion_score * 0.4 + color_score * 0.3)
        return total_score > 0.35
    except:
        return False

def detect_motion_intensity(frame):
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        intensity = np.sum(edges) / (frame.shape[0] * frame.shape[1])
        return min(intensity / 50.0, 1.0)
    except:
        return 0.0

def detect_basketball_colors(frame):
    try:
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        orange_mask = cv2.inRange(hsv, np.array([5, 50, 50]), np.array([25, 255, 255]))
        red_mask1 = cv2.inRange(hsv, np.array([0, 50, 50]), np.array([10, 255, 255]))
        red_mask2 = cv2.inRange(hsv, np.array([170, 50, 50]), np.array([180, 255, 255]))
        red_mask = red_mask1 + red_mask2
        orange_ratio = np.sum(orange_mask) / (frame.shape[0] * frame.shape[1] * 255)
        red_ratio = np.sum(red_mask) / (frame.shape[0] * frame.shape[1] * 255)
        return min((orange_ratio + red_ratio) * 10, 1.0)
    except:
        return 0.0

def create_clip_file(video_path, center_time, duration, fps, clip_num):
    start_time = max(0, center_time - duration/2)
    end_time = center_time + duration/2
    output_dir = "highlights"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"{output_dir}/highlight_{clip_num}_{timestamp}.mp4"
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None
    try:
        start_frame = int(start_time * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        max_frames = int(duration * fps)
        for _ in range(max_frames):
            ret, frame = cap.read()
            if not ret:
                break
            out.write(frame)
        out.release()
        cap.release()
        return output_path
    except:
        cap.release()
        if os.path.exists(output_path):
            os.remove(output_path)
        return None

def test_with_local_video():
    video_path = r"C:\Users\ì´ë™í˜„\Desktop\shootpoint\basketball_strong.mp4"
    jersey_path = r"C:\Users\ì´ë™í˜„\Desktop\shootpoint\jersey_img.png"
    if not os.path.exists(video_path) or not os.path.exists(jersey_path):
        print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    try:
        with open(jersey_path, 'rb') as f:
            img_array = np.frombuffer(f.read(), np.uint8)
        jersey_img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        if jersey_img is None:
            print("âŒ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
            return
        if jersey_img.shape[0] > 200 or jersey_img.shape[1] > 200:
            scale = min(200/jersey_img.shape[1], 200/jersey_img.shape[0])
            jersey_img = cv2.resize(jersey_img, (int(jersey_img.shape[1]*scale), int(jersey_img.shape[0]*scale)))
    except Exception as e:
        print(f"âŒ ë“±ë²ˆí˜¸ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return
    try:
        highlights = run_score_detection(video_path, jersey_img)
        print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì´ {len(highlights)}ê°œ ìƒì„±")
        for h in highlights:
            print(f"   â° ì‹œê°„: {h['time']:.1f}ì´ˆ | ğŸ“ íŒŒì¼: {h['clip_path']} | â±ï¸  ê¸¸ì´: {h['duration']}ì´ˆ")
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    test_with_local_video()
