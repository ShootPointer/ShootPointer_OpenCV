# app/services/jersey.py
from __future__ import annotations
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any
import subprocess
import re
import tempfile
import shutil
import logging
import time

import cv2
import numpy as np
import pytesseract

from app.core.config import settings
from app.services.ffmpeg import get_duration

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CUDA helpers (ì„ íƒì  ê°€ì†)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _cuda_available() -> bool:
    """OpenCVê°€ CUDA ë¹Œë“œì´ê³  USE_CUDA=trueì´ë©´ True."""
    try:
        return bool(settings.USE_CUDA) and cv2.cuda.getCudaEnabledDeviceCount() > 0
    except Exception:
        return False

def _fast_resize(img: np.ndarray, fx: float, fy: float) -> np.ndarray:
    """CUDA ê°€ëŠ¥í•˜ë©´ GPU resize, ì•„ë‹ˆë©´ CPU resize."""
    if fx == 1.0 and fy == 1.0:
        return img
    if _cuda_available():
        try:
            gpu = cv2.cuda_GpuMat()
            gpu.upload(img)
            new_w = int(round(img.shape[1] * fx))
            new_h = int(round(img.shape[0] * fy))
            gpu_resized = cv2.cuda.resize(gpu, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
            return gpu_resized.download()
        except Exception:
            # GPU ê²½ë¡œ ì‹¤íŒ¨ ì‹œ CPU í´ë°±
            pass
    return cv2.resize(img, None, fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)

def _maybe_downscale_for_cuda(bgr: np.ndarray) -> np.ndarray:
    """
    ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ê¸´ ë³€ ê¸°ì¤€ìœ¼ë¡œ CUDA_RESIZE_MAXì— ë§ì¶”ì–´ ë¯¸ë¦¬ ì¶•ì†Œ.
    CPU ê²½ë¡œì—ì„œë„ ê³¼ë„í•œ ë©”ëª¨ë¦¬/ì‹œê°„ì„ ì¤„ì´ëŠ” íš¨ê³¼.
    """
    try:
        max_side = int(getattr(settings, "CUDA_RESIZE_MAX", 1920))
        if max_side <= 0:
            return bgr
        h, w = bgr.shape[:2]
        long_side = max(h, w)
        if long_side > max_side:
            scale = max_side / float(long_side)
            return _fast_resize(bgr, scale, scale)
    except Exception:
        pass
    return bgr

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FFmpeg helpers (íƒ€ì„ì•„ì›ƒ/ë¡œê¹… í¬í•¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _run(cmd: list[str]) -> subprocess.CompletedProcess:
    """ê³µí†µ ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰(íƒ€ì„ì•„ì›ƒ/ë¡œê¹… í¬í•¨)"""
    to = settings.FFMPEG_TIMEOUT_SEC
    try:
        logger.debug(f"[jersey.ffproc] exec (timeout={to}s): {' '.join(cmd[:8])} ...")
        p = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=to,
        )
        logger.debug(f"[jersey.ffproc] returncode={p.returncode}")
        return p
    except subprocess.TimeoutExpired:
        logger.warning(f"[jersey.ffproc] timeout after {to}s")
        raise
    except Exception as e:
        logger.exception(f"[jersey.ffproc] failed: {e}")
        raise

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë ˆì„ ìƒ˜í”Œë§ (ì„¸ê·¸ë¨¼íŠ¸ ê²€ì¶œì—ì„œ ì‚¬ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _sample_frames_to_dir(video_path: Path, fps: float) -> tuple[Path, list[tuple[float, Path]]]:
    """
    ffmpegë¡œ ì¼ì • fps ê°„ê²© í”„ë ˆì„ì„ ì¶”ì¶œí•˜ê³  showinfo ë¡œê·¸ì—ì„œ pts_time(ì´ˆ)ì„ íŒŒì‹±.
    (ì˜µì…˜) settings.FFMPEG_HWACCEL,* ì„¤ì • ì‹œ í•˜ë“œì›¨ì–´ ê°€ì† ë””ì½”ë”© ì‚¬ìš©.
    """
    assert video_path.exists(), f"input not found: {video_path}"
    tmp_dir = Path(tempfile.mkdtemp(prefix="jersey_"))
    out_pattern = tmp_dir / "f_%05d.jpg"

    vf = f"fps={fps},scale='min(960,iw)':-2,showinfo"

    cmd = ["ffmpeg", "-y"]
    # í•˜ë“œì›¨ì–´ ê°€ì†(ì˜µì…˜) â€” configì˜ FFMPEG_HWACCEL / FFMPEG_HWACCEL_DEVICE ì‚¬ìš©
    if getattr(settings, "FFMPEG_HWACCEL", ""):
        cmd += ["-hwaccel", settings.FFMPEG_HWACCEL]
        if getattr(settings, "FFMPEG_HWACCEL_DEVICE", ""):
            cmd += ["-hwaccel_device", settings.FFMPEG_HWACCEL_DEVICE]

    cmd += [
        "-i", str(video_path),
        "-vf", vf,
        "-q:v", "3",
        str(out_pattern),
    ]

    proc = _run(cmd)

    times: list[float] = []
    for line in (proc.stderr or "").splitlines():
        m = re.search(r"pts_time:([0-9]+\.[0-9]+)", line)
        if m:
            try:
                times.append(float(m.group(1)))
            except Exception:
                pass

    images = sorted(tmp_dir.glob("f_*.jpg"))
    pairs: list[tuple[float, Path]] = []
    for i, img in enumerate(images):
        if i < len(times):
            pairs.append((times[i], img))

    logger.info(f"[jersey.sample] frames={len(pairs)} (fps={fps})")
    return tmp_dir, pairs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ROI íƒìƒ‰(ìˆ«ì í›„ë³´)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _digit_roi_candidates(gray: np.ndarray) -> list[np.ndarray]:
    """
    ìˆ«ì í›„ë³´ ROI ì¶”ì¶œ: ë¸”ëŸ¬ â†’ ì ì‘í˜• ì´ì§„í™” â†’ ëª¨í´ë¡œì§€ â†’ ì»¨íˆ¬ì–´ í•„í„°.
    ìƒë‹¨ HUD(ìŠ¤ì½”ì–´ë³´ë“œ) ì˜¤ê²€ì„ ì¤„ì´ê¸° ìœ„í•´ í™”ë©´ ìƒë‹¨ ì¼ë¶€ëŠ” ì œì™¸.
    """
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    thr = cv2.adaptiveThreshold(
        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 7
    )
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    mor = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)

    contours, _ = cv2.findContours(mor, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    rois: list[np.ndarray] = []
    H, W = gray.shape[:2]
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        # ğŸ”§ ì¡ìŒ ì–µì œ: ìµœì†Œ ë©´ì  ìƒí–¥(400 â†’ 700)
        if w * h < 700:
            continue
        ar = w / (h + 1e-6)
        if ar < 0.3 or ar > 6.0:
            continue
        if y < H * 0.1:  # í™”ë©´ ìƒë‹¨ 10%ëŠ” HUDì¼ í™•ë¥ â†‘ â†’ ì œì™¸(í•„ìš”ì‹œ 0.15~0.2ë¡œ ì¡°ì ˆ)
            continue
        x0 = max(0, x - 2)
        y0 = max(0, y - 2)
        x1 = min(W, x + w + 2)
        y1 = min(H, y + h + 2)
        roi = gray[y0:y1, x0:x1]
        # ğŸ”§ ëŠê¸´ íš ë³´ì •: ROIì— close í•œ ë²ˆ ë”
        roi = cv2.morphologyEx(roi, cv2.MORPH_CLOSE, kernel, iterations=1)
        rois.append(roi)
    return rois

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OCR ìœ í‹¸ (ê°•í™” ë£¨í‹´)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _final_conf(digits: str, conf_vals: list[float]) -> float:
    """
    OCR confê°€ ëˆ„ë½/ìŒìˆ˜(-1)ì¸ ê²½ìš°ë¥¼ ìœ„í•œ ë³´ì • ê·œì¹™.
    - conf_vals ìˆìœ¼ë©´ í‰ê· ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ì—†ìœ¼ë©´ ìë¦¿ìˆ˜ë³„ ê¸°ë³¸ê°’(ë‹¨ì¼ì:0.85, ë‘ ìë¦¬:0.90, ê·¸ ì™¸:0.80)
    """
    if conf_vals:
        return float(np.mean(conf_vals))
    n = len(digits)
    if n == 1:
        return 0.85
    if n == 2:
        return 0.90
    return 0.80

def _tess_digits_with_conf(img: np.ndarray, psm: int) -> tuple[str, float]:
    """
    pytesseract image_to_dataë¡œ ìˆ«ìì™€ í‰ê·  confidence(0~1)ë¥¼ ì–»ëŠ”ë‹¤.
    settings.OCR_TIMEOUT_SEC ì ìš© + conf ë³´ì •.
    """
    config = (
        f"-l eng --oem {settings.JERSEY_TESSERACT_OEM} "
        f"--psm {psm} -c tessedit_char_whitelist=0123456789"
    )
    try:
        data = pytesseract.image_to_data(
            img, config=config, output_type=pytesseract.Output.DICT, timeout=settings.OCR_TIMEOUT_SEC
        )
    except RuntimeError as e:
        logger.warning(f"[jersey.ocr] timeout after {settings.OCR_TIMEOUT_SEC}s: {e}")
        return "", 0.0
    except Exception as e:
        logger.exception(f"[jersey.ocr] failed: {e}")
        return "", 0.0

    texts = data.get("text", []) or []
    confs = data.get("conf", []) or []
    digits = ""
    conf_vals: list[float] = []

    for t, c in zip(texts, confs):
        t = t or ""
        only = re.sub(r"\D+", "", t)
        if only:
            digits += only
            try:
                ci = float(c)
                if ci >= 0:
                    conf_vals.append(ci / 100.0)
            except Exception:
                pass

    if not digits:
        return "", 0.0

    conf = _final_conf(digits, conf_vals)
    return digits, conf

def _prep_variants(bgr: np.ndarray, invert: bool) -> list[np.ndarray]:
    """
    ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë³€í˜•: ê·¸ë ˆì´, CLAHE, Otsu, Adaptive, Morph
    """
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    if invert:
        gray = cv2.bitwise_not(gray)

    outs = [gray]

    # CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(gray)
    outs.append(clahe)

    # Otsu
    _, otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    outs.append(otsu)

    # Adaptive
    adap = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 7
    )
    outs.append(adap)

    # Morph close
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    mor = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel, iterations=1)
    outs.append(mor)

    return outs

def _best_digits_with_hint(digs: list[tuple[str, float]], expected: str | None) -> tuple[str, float]:
    if not digs:
        return "", 0.0
    if expected:
        def _score(cand: tuple[str, float]):
            d, c = cand
            # ì •í™•ì¼ì¹˜(2) > ë¶€ë¶„ì¼ì¹˜(1) > ë¶ˆì¼ì¹˜(0), ë™ë¥ ì´ë©´ conf, ê¸¸ì´ì°¨ì´ ì‘ì€ ìª½ ìš°ì„ 
            pri = 2 if d == expected else (1 if expected in d else 0)
            return (pri, c, -abs(len(d) - len(expected)))
        digs = sorted(digs, key=_score, reverse=True)
        return digs[0]
    # íŒíŠ¸ ì—†ìœ¼ë©´: ê¸¸ì´ ìš°ì„  â†’ conf
    digs = sorted(digs, key=lambda x: (len(x[0]), x[1]), reverse=True)
    return digs[0]

def _ocr_try_all(bgr: np.ndarray, expected: str | None = None) -> tuple[str, float, Dict[str, Any]]:
    """
    ë©€í‹° ìŠ¤ì¼€ì¼ Ã— ë°˜ì „ Ã— ì „ì²˜ë¦¬ Ã— PSM ì¡°í•©ìœ¼ë¡œ ìµœì  ê²°ê³¼ íƒìƒ‰.
    - ì˜ˆì‚°(ì½¤ë³´ ìˆ˜/ì´ ì†Œìš”ì‹œê°„) ì´ˆê³¼ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
    - íŒíŠ¸(expected)ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ì¦‰ì‹œ ë‹¨ë½(short-circuit)
    """
    # ë„ˆë¬´ í¬ë©´ ë¯¸ë¦¬ ì¶•ì†Œ(ì†ë„/ë©”ëª¨ë¦¬)
    bgr = _maybe_downscale_for_cuda(bgr)

    H, W = bgr.shape[:2]
    tried = 0
    candidates: list[tuple[str, float]] = []

    scales = getattr(settings, "OCR_SCALES", [1.0]) or [1.0]
    psms = getattr(settings, "OCR_PSMS", [7, 6, 10]) or [7, 6, 10]
    invert_opts = [False, True] if getattr(settings, "OCR_TRY_INVERT", True) else [False]

    # ğŸ”§ ì˜ˆì‚°(ìµœëŒ€ ì¡°í•©/ìµœëŒ€ ì‹œê°„) â€” .envì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    max_combos = int(getattr(settings, "OCR_MAX_COMBOS", 120))
    max_sec = float(getattr(settings, "OCR_MAX_SEC", 8.0))
    t0 = time.perf_counter()

    def over_budget() -> bool:
        return (tried >= max_combos) or ((time.perf_counter() - t0) >= max_sec)

    for s in scales:
        scaled = _fast_resize(bgr, s, s) if s != 1.0 else bgr
        for inv in invert_opts:
            variants = _prep_variants(scaled, invert=inv)

            # â‘  ì „ì²´ ì´ë¯¸ì§€
            for v in variants:
                for psm in psms:
                    tried += 1
                    digs, cf = _tess_digits_with_conf(v, psm=psm)
                    digs = re.sub(r"\D+", "", digs)
                    if digs:
                        candidates.append((digs, cf))
                        if expected and digs == expected:
                            # ì˜ˆìƒê°’ ì •í™• ì¼ì¹˜ â†’ ì¦‰ì‹œ ë°˜í™˜
                            return digs, cf, {
                                "imageWidth": W, "imageHeight": H,
                                "triedCombos": tried, "numCandidates": len(candidates),
                                "shortCircuit": "expected_match"
                            }
                    if over_budget():
                        digits, conf = _best_digits_with_hint(candidates, expected)
                        dbg = {
                            "imageWidth": W, "imageHeight": H,
                            "triedCombos": tried, "numCandidates": len(candidates),
                            "budgetStop": True
                        }
                        return digits, float(conf), dbg

            # â‘¡ ROIë“¤
            gray = cv2.cvtColor(scaled, cv2.COLOR_BGR2GRAY)
            if inv:
                gray = cv2.bitwise_not(gray)
            rois = _digit_roi_candidates(gray)
            for roi in rois:
                for fx in (1.5, 2.0, 3.0):
                    roi_big = _fast_resize(roi, fx, fx)
                    for psm in psms:
                        tried += 1
                        digs, cf = _tess_digits_with_conf(roi_big, psm=psm)
                        digs = re.sub(r"\D+", "", digs)
                        if digs:
                            candidates.append((digs, cf))
                            if expected and digs == expected:
                                return digs, cf, {
                                    "imageWidth": W, "imageHeight": H,
                                    "triedCombos": tried, "numCandidates": len(candidates),
                                    "shortCircuit": "expected_match"
                                }
                        if over_budget():
                            digits, conf = _best_digits_with_hint(candidates, expected)
                            dbg = {
                                "imageWidth": W, "imageHeight": H,
                                "triedCombos": tried, "numCandidates": len(candidates),
                                "budgetStop": True
                            }
                            return digits, float(conf), dbg

    digits, conf = _best_digits_with_hint(candidates, expected)
    debug: Dict[str, Any] = {
        "imageWidth": W, "imageHeight": H,
        "triedCombos": tried, "numCandidates": len(candidates)
    }
    if getattr(settings, "DEBUG_OCR", False):
        top = sorted(candidates, key=lambda x: (len(x[0]), x[1]), reverse=True)[:5]
        debug["topCandidates"] = [{"digits": d, "conf": round(c, 3)} for d, c in top]
    return digits, float(conf), debug

# âœ… íŒíŠ¸ ì§€ì› ê³µê°œ API (ë¼ìš°í„°ì—ì„œ backNumber íŒíŠ¸ ì‚¬ìš©)
def ocr_jersey_image_bytes_with_hint(image_bytes: bytes, expected: str | None) -> tuple[str, float]:
    if not image_bytes:
        return "", 0.0
    arr = np.frombuffer(image_bytes, dtype=np.uint8)
    bgr = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if bgr is None:
        return "", 0.0
    bgr = _maybe_downscale_for_cuda(bgr)
    digits, conf, _ = _ocr_try_all(bgr, expected=expected)
    return digits, conf

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µê°œ OCR API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ocr_jersey_image_bytes(image_bytes: bytes) -> tuple[str, float]:
    """
    ì—…ë¡œë“œëœ ë“±ë²ˆí˜¸ 'ì´ë¯¸ì§€'ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ.
    ë°˜í™˜: (digits, conf) â€” confëŠ” 0.0~1.0
    (ê¸°ì¡´ ë¼ìš°í„°ì™€ì˜ í˜¸í™˜ì„ ìœ„í•´ 2-íŠœí”Œ ìœ ì§€)
    """
    if not image_bytes:
        return "", 0.0
    arr = np.frombuffer(image_bytes, dtype=np.uint8)
    bgr = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if bgr is None:
        return "", 0.0
    bgr = _maybe_downscale_for_cuda(bgr)
    digits, conf, _dbg = _ocr_try_all(bgr)
    return digits, conf

def ocr_jersey_image_bytes_debug(image_bytes: bytes) -> tuple[str, float, Dict[str, Any]]:
    """
    ë””ë²„ê·¸ ì •ë³´ê¹Œì§€ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©.
    ë°˜í™˜: (digits, conf, debugDict)
    """
    if not image_bytes:
        return "", 0.0, {"reason": "empty"}
    arr = np.frombuffer(image_bytes, dtype=np.uint8)
    bgr = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if bgr is None:
        return "", 0.0, {"reason": "decode_failed"}
    bgr = _maybe_downscale_for_cuda(bgr)
    return _ocr_try_all(bgr)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# time utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _merge_times(times: list[float], max_gap: float) -> list[tuple[float, float]]:
    """ê²€ì¶œ ì‹œì ë“¤ì„ ì¸ì ‘ ê°„ê²©(max_gap) ê¸°ì¤€ìœ¼ë¡œ [start,end] êµ¬ê°„ìœ¼ë¡œ ë¬¶ê¸°."""
    if not times:
        return []
    times = sorted(times)
    segs: list[tuple[float, float]] = []
    s = e = times[0]
    for t in times[1:]:
        if t - e <= max_gap:
            e = t
        else:
            segs.append((s, e))
            s = e = t
    segs.append((s, e))
    return segs

def _expand_and_filter(
    segs: list[tuple[float, float]],
    pad: float,
    min_dur: float,
    total: float,
) -> list[tuple[float, float]]:
    """êµ¬ê°„ ì•ë’¤ pad í™•ì¥ í›„, ë„ˆë¬´ ì§§ì€ êµ¬ê°„ ì œê±° + [0,total] ë²”ìœ„ í´ë¨í”„."""
    out: list[tuple[float, float]] = []
    for s, e in segs:
        s2 = max(0.0, s - pad)
        e2 = min(total, e + pad)
        if e2 - s2 >= min_dur:
            out.append((s2, e2))
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main API: ì„¸ê·¸ë¨¼íŠ¸ ê²€ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_player_segments(
    video_path: Path, jersey_number: int
) -> List[Tuple[float, float]]:
    """
    ê°„ë‹¨í•œ ë“±ë²ˆí˜¸ ê°ì§€ íŒŒì´í”„ë¼ì¸:
      1) fpsë¡œ í”„ë ˆì„ ìƒ˜í”Œë§ (ffmpeg)
      2) ìˆ«ì í›„ë³´ ROI ì¶”ì¶œ(OpenCV) â†’ ê°•í™”ëœ Tesseract OCR(ìˆ«ìë§Œ)
      3) jersey_numberì™€ ì¼ì¹˜í•˜ëŠ” í”„ë ˆì„ì˜ ì‹œì ë“¤ì„ ë³‘í•©í•´ êµ¬ê°„ ë°˜í™˜
    """
    assert video_path.exists(), f"input not found: {video_path}"

    fps = settings.JERSEY_SAMPLE_FPS
    min_seg = settings.JERSEY_MIN_SEG_DUR
    merge_gap = settings.JERSEY_MERGE_GAP
    num_conf = settings.JERSEY_NUM_CONF

    tmp_dir: Optional[Path] = None
    try:
        tmp_dir, frames = _sample_frames_to_dir(video_path, fps=fps)
        total = get_duration(video_path)
        target = str(jersey_number)

        hit_times: list[float] = []
        for t, img_path in frames:
            img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)
            if img is None:
                continue

            # í›„ë³´ ROIë“¤ì— ëŒ€í•´ ë¹ ë¥¸ ê²½ë¡œë¡œ OCR
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            rois = _digit_roi_candidates(gray)
            found = False

            # ROI ìš°ì„ (ì†ë„): ê° ROI 2ë°°/3ë°° Ã— ë¹ ë¥¸ PSM ì„¸íŠ¸
            fast_psms = settings.OCR_PSMS or [7, 6, 10]
            for roi in rois:
                for fx in (2.0, 3.0):
                    roi_big = _fast_resize(roi, fx, fx)
                    for psm in fast_psms:
                        digs, cf = _tess_digits_with_conf(roi_big, psm=psm)
                        digs = re.sub(r"\D+", "", digs)
                        if digs and target in digs and cf >= num_conf:
                            found = True
                            break
                    if found:
                        break
                if found:
                    break

            # ROIì—ì„œ ëª» ì°¾ìœ¼ë©´, ì´ë¯¸ì§€ ì „ì²´ë¥¼ ë³´ì¡° íƒìƒ‰(ì˜ˆì‚° ë‚´)
            if not found:
                img_small = _maybe_downscale_for_cuda(img)
                digits, cf, _ = _ocr_try_all(img_small, expected=target)
                if digits and target in digits and cf >= num_conf:
                    found = True

            if found:
                hit_times.append(t)

        # ì‹œì  â†’ êµ¬ê°„ ë³‘í•©, í™•ì¥, ìµœì†Œ ê¸¸ì´ í•„í„°
        segs = _merge_times(hit_times, max_gap=merge_gap)
        segs = _expand_and_filter(segs, pad=0.5, min_dur=min_seg, total=total)
        logger.info(f"[jersey.segs] jersey={jersey_number} hits={len(hit_times)} segments={len(segs)}")
        return segs

    finally:
        # ì„ì‹œ í”„ë ˆì„ í´ë” ì •ë¦¬
        if tmp_dir:
            try:
                shutil.rmtree(tmp_dir, ignore_errors=True)
            except Exception:
                pass
