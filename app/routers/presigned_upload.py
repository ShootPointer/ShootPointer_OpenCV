from __future__ import annotations

import logging
import shutil
import base64
from pathlib import Path
from typing import Annotated

from fastapi import APIRouter, Depends, Form, File, UploadFile, HTTPException, BackgroundTasks

from app.core.config import settings
from app.core.crypto import AESGCMCrypto, DecryptedToken, get_crypto_service

logger = logging.getLogger(__name__)
router = APIRouter()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¹„ë™ê¸° AI ë°ëª¨ íŠ¸ë¦¬ê±° (placeholder)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def trigger_ai_demo(job_id: str, final_path: Path) -> None:
    """
    ì›ë³¸ ì˜ìƒ ì €ì¥ ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ëŠ” placeholder í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        # TODO: Redis íì— job_idì™€ final_pathë¥¼ pushí•˜ëŠ” ì‹¤ì œ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.
        logger.info(f"AI Demo Triggered (Placeholder) for Job ID: {job_id}. Source: {final_path}")
        logger.info(f"AI processing successfully initiated for {job_id}")
    except Exception as e:
        logger.error(f"Failed to trigger AI demo for {job_id}: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Depends íƒ€ì… ë³„ì¹­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CryptoDep = Annotated[AESGCMCrypto, Depends(get_crypto_service)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/chunk")
async def upload_presigned_chunk(
    # â¬‡â¬‡ ê¸°ë³¸ê°’ ì—†ëŠ” íŒŒë¼ë¯¸í„°(Depends ì£¼ì…)ëŠ” ë§¨ ì•ì— ë‘”ë‹¤ (íŒŒì´ì¬ ê·œì¹™ ì¶©ì¡±)
    crypto: CryptoDep,
    background_tasks: BackgroundTasks,

    # â¬‡â¬‡ ê¸°ë³¸ê°’ ìˆëŠ” íŒŒë¼ë¯¸í„°ë“¤ (Form/File)
    file: UploadFile = File(..., description="Base64 ì¸ì½”ë”©ëœ ì²­í¬ ë°ì´í„°"),
    chunkIndex: int = Form(..., ge=1, description="í˜„ì¬ ì²­í¬ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)"),
    totalParts: int = Form(..., ge=1, description="ì „ì²´ ì²­í¬ ê°œìˆ˜"),
    presignedToken: str = Form(..., description="AES-GCM ë³µí˜¸í™” ê°€ëŠ¥í•œ í† í°"),
    fileName: str = Form(..., description="í´ë¼ì´ì–¸íŠ¸ê°€ ì—…ë¡œë“œí•˜ëŠ” íŒŒì¼ëª…"),
):
    """
    í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° Base64 ì¸ì½”ë”©ëœ ì²­í¬ë¥¼ ë°›ì•„ ë””ì½”ë”© ë° ì €ì¥
    """
    job_id = None
    token_file_name = None
    try:
        # 1) í† í° ë³µí˜¸í™”/ê²€ì¦
        try:
            token_data: DecryptedToken = crypto.decrypt_token(presignedToken)
            job_id = token_data.jobId
            token_file_name = token_data.fileName
        except ValueError as e:
            # ğŸš¨ JSON serializable ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ValueError ë°œìƒ ì‹œ HTTPExceptionìœ¼ë¡œ ë³€í™˜ (í•µì‹¬ ìˆ˜ì •)
            logger.error(f"Token validation failed (ValueError): {e}")
            raise HTTPException(status_code=401, detail=f"Invalid or expired token: {str(e)}")


        # 2) fileName ì¼ì¹˜ ê²€ì¦
        if fileName != token_file_name:
            logger.error(f"Filename mismatch for Job {job_id}: Token expects '{token_file_name}', received '{fileName}'")
            raise HTTPException(
                status_code=400,
                detail=f"Filename mismatch: Token expects '{token_file_name}', received '{fileName}'",
            )
        
        # 3) Base64 ë°ì´í„° ì½ê¸° ë° ë””ì½”ë”©
        base64_data: bytes = await file.read() 
        
        try:
            # Base64 ë¬¸ìì—´ì„ ì‹¤ì œ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ë””ì½”ë”©
            chunk_binary_data = base64.b64decode(base64_data.strip())
        except (ValueError, Exception) as e:
            # Base64 ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ 400 Bad Request ë° ë¡œê·¸ ê¸°ë¡
            logger.error(f"Base64 decoding failed for chunk {chunkIndex} (Job {job_id}): {e}")
            raise HTTPException(status_code=400, detail="Invalid Base64 data received in chunk.")


        # 4) ì²­í¬ ì €ì¥ ê²½ë¡œ ì„¤ì •
        chunk_dir = settings.TEMP_ROOT / job_id
        chunk_dir.mkdir(parents=True, exist_ok=True)

        chunk_filename = f"{job_id}_{token_file_name}.{chunkIndex:04d}"
        chunk_path = chunk_dir / chunk_filename

        # 5) ë””ì½”ë”©ëœ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì“°ê¸°
        with chunk_path.open("wb") as buffer:
            buffer.write(chunk_binary_data)
        
        logger.info(f"Chunk {chunkIndex}/{totalParts} saved for Job ID: {job_id}")
        return {"message": "Chunk uploaded successfully", "jobId": job_id, "chunkIndex": chunkIndex}

    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        # ê·¸ ì™¸ ëª¨ë“  ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ì— ëŒ€í•´ 500 ì‘ë‹µ
        logger.error(f"Unexpected Error during chunk upload: {e}", exc_info=True)
        # JSON ì§ë ¬í™” ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ HTTPExceptionìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        raise HTTPException(status_code=500, detail="Internal server error during upload")

@router.post("/complete")
async def complete_presigned_upload(
    # â¬‡â¬‡ ê¸°ë³¸ê°’ ì—†ëŠ” íŒŒë¼ë¯¸í„° ë¨¼ì €
    crypto: CryptoDep,
    background_tasks: BackgroundTasks,
    # redis_service: RedisDep, # Redis ì˜ì¡´ì„± ì œê±°ë¨

    # â¬‡â¬‡ ê¸°ë³¸ê°’ ìˆëŠ” Form íŒŒë¼ë¯¸í„°ë“¤
    totalParts: int = Form(..., ge=1, description="ì „ì²´ ì²­í¬ ê°œìˆ˜"),
    presignedToken: str = Form(..., description="AES-GCM ë³µí˜¸í™” ê°€ëŠ¥í•œ í† í°"),
):
    """
    ì²­í¬ ì™„ë£Œ í™•ì¸ â†’ ë³‘í•© â†’ AI ì²˜ë¦¬ íŠ¸ë¦¬ê±° (Placeholder ìœ ì§€)
    """
    job_id = None
    chunk_dir = None
    try:
        # 1) í† í° ë³µí˜¸í™”/ê²€ì¦
        try:
            token_data: DecryptedToken = crypto.decrypt_token(presignedToken)
            job_id = token_data.jobId
            file_name = token_data.fileName
        except ValueError as e:
            # ğŸš¨ JSON serializable ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ValueError ë°œìƒ ì‹œ HTTPExceptionìœ¼ë¡œ ë³€í™˜ (í•µì‹¬ ìˆ˜ì •)
            logger.error(f"Token validation failed in /complete: {e}")
            raise HTTPException(status_code=401, detail=f"Invalid or expired token: {str(e)}")


        chunk_dir = settings.TEMP_ROOT / job_id
        if not chunk_dir.exists():
            raise HTTPException(status_code=404, detail="Job ID not found or no chunks uploaded.")

        # 2) ê°œìˆ˜ ê²€ì¦
        chunk_files = sorted(chunk_dir.glob(f"{job_id}_{file_name}.*"))
        actual_parts = len(chunk_files)
        if actual_parts != totalParts:
            logger.error(
                f"Integrity check failed for Job {job_id}: Expected {totalParts} parts, found {actual_parts}."
            )
            shutil.rmtree(chunk_dir) # ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
            raise HTTPException(
                status_code=400,
                detail=f"Incomplete upload: Expected {totalParts} chunks, but only {actual_parts} were received.",
            )

        # 3) ë³‘í•©
        final_path = settings.ORIGINAL_VIDEO_ROOT / f"{job_id}_{file_name}"
        final_path.parent.mkdir(parents=True, exist_ok=True)

        with final_path.open("wb") as outfile:
            for chunk_file in chunk_files:
                with chunk_file.open("rb") as infile:
                    shutil.copyfileobj(infile, outfile)

        logger.info(f"File merged successfully: {final_path}")

        # 4) ì„ì‹œ ì²­í¬ í´ë” ì •ë¦¬
        shutil.rmtree(chunk_dir)

        # 5) AI ë°ëª¨ ë¹„ë™ê¸° ì‹œì‘ (Placeholder ìœ ì§€)
        background_tasks.add_task(trigger_ai_demo, job_id, final_path)
        logger.info(f"AI processing successfully initiated (via background task).")

        return {"message": "Upload complete, file merged, and AI processing initiated", "jobId": job_id}

    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"Error during completion: {e}")
        if 'chunk_dir' in locals() and chunk_dir and chunk_dir.exists():
            shutil.rmtree(chunk_dir, ignore_errors=True)
        # JSON ì§ë ¬í™” ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ HTTPExceptionìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        raise HTTPException(status_code=500, detail="Internal server error during file merge")