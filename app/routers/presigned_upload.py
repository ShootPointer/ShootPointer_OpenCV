from __future__ import annotations

import logging
import shutil
import base64
from pathlib import Path
from typing import Annotated, Optional # Optional (ë˜ëŠ” | None) import

# ğŸš¨ ìˆ˜ì •: File, UploadFile ì œê±° (Formë§Œ ì‚¬ìš©)
from fastapi import APIRouter, Depends, Form, HTTPException, BackgroundTasks

from app.core.config import settings
from app.core.crypto import AESGCMCrypto, DecryptedToken, get_crypto_service

logger = logging.getLogger(__name__)
router = APIRouter()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¹„ë™ê¸° AI ë°ëª¨ íŠ¸ë¦¬ê±° (placeholder)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def trigger_ai_demo(job_id: str, final_path: Path) -> None:
    """
    ì›ë³¸ ì˜ìƒ ì €ì¥ ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ëŠ” placeholder í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        # TODO: ì‹¤ì œ í/ì¡ íŠ¸ë¦¬ê±° ë¡œì§ìœ¼ë¡œ êµì²´
        logger.info(f"AI Demo Triggered (Placeholder) for Job ID: {job_id}. Source: {final_path}")
        logger.info(f"AI processing successfully initiated for {job_id}")
    except Exception as e:
        logger.error(f"Failed to trigger AI demo for {job_id}: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Depends íƒ€ì… ë³„ì¹­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CryptoDep = Annotated[AESGCMCrypto, Depends(get_crypto_service)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸: Base64(any) ë””ì½”ë”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _b64_any_decode(s: str) -> bytes:
    """
    URL-safe / í‘œì¤€ Base64 ëª¨ë‘ ìˆ˜ìš©. í•„ìš” ì‹œ íŒ¨ë”© ë³´ì • í›„ ë””ì½”ë“œ.
    """
    s = s.strip()
    if not s:
        return b""
    # data URL prefix ì œê±° ëŒ€ì‘ (ex: "data:application/octet-stream;base64,AAAA...")
    if "," in s and s.lstrip().lower().startswith("data:"):
        s = s.split(",", 1)[1].strip()
    
    # Base64 íŒ¨ë”© ë³´ì • (4ì˜ ë°°ìˆ˜)
    pad = "=" * ((4 - (len(s) % 4)) % 4)
    
    # URL-safe ë¨¼ì € ì‹œë„ í›„, ì‹¤íŒ¨ ì‹œ í‘œì¤€ Base64 ì‹œë„
    try:
        return base64.urlsafe_b64decode(s + pad)
    except Exception:
        return base64.b64decode(s + pad)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post("/chunk")
async def upload_presigned_chunk(
    # â¬‡â¬‡ ê¸°ë³¸ê°’ ì—†ëŠ” íŒŒë¼ë¯¸í„°(Depends ì£¼ì…)ëŠ” ë§¨ ì•ì— ë‘”ë‹¤ (íŒŒì´ì¬ ê·œì¹™ ì¶©ì¡±)
    crypto: CryptoDep,
    background_tasks: BackgroundTasks,

    # â¬‡â¬‡ ê¸°ë³¸ê°’ ìˆëŠ” íŒŒë¼ë¯¸í„°ë“¤ (Form)
    # ğŸš¨ ìˆ˜ì •: file: UploadFile ëŒ€ì‹  base64Chunk: strë¡œ Base64 ë¬¸ìì—´ì„ Formìœ¼ë¡œ ë°›ìŒ
    base64Chunk: str = Form(..., description="Base64 ì¸ì½”ë”©ëœ ì²­í¬ ë¬¸ìì—´"),
    
    chunkIndex: int = Form(..., ge=1, description="í˜„ì¬ ì²­í¬ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)"),
    totalParts: int = Form(..., ge=1, description="ì „ì²´ ì²­í¬ ê°œìˆ˜"),
    presignedToken: str = Form(..., description="AES-GCM ë³µí˜¸í™” ê°€ëŠ¥í•œ í† í°"),
    fileName: str = Form(..., description="í´ë¼ì´ì–¸íŠ¸ê°€ ì—…ë¡œë“œí•˜ëŠ” íŒŒì¼ëª…"),
):
    """
    í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° Base64 ì¸ì½”ë”©ëœ ì²­í¬ë¥¼ ë°›ì•„ ë””ì½”ë”© ë° ì €ì¥
    """
    # Optional íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì„ ì–¸
    job_id: str | None = None
    token_file_name: str | None = None
    
    try:
        # 0) ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€ (chunkIndexì™€ totalPartsëŠ” FastAPI/Pydanticì´ ì´ë¯¸ ê²€ì‚¬í•¨)
        if chunkIndex > totalParts:
            raise HTTPException(status_code=400, detail="chunkIndex cannot be greater than totalParts.")

        # 1) í† í° ë³µí˜¸í™”/ê²€ì¦
        try:
            token_data: DecryptedToken = crypto.decrypt_token(presignedToken)
            job_id = token_data.jobId
            token_file_name = token_data.fileName
        except ValueError as e:
            logger.error(f"Token validation failed (ValueError): {e}")
            raise HTTPException(status_code=401, detail=f"Invalid or expired token: {str(e)}")

        # 2) fileName ì¼ì¹˜ ê²€ì¦
        if fileName != token_file_name:
            logger.error(
                f"Filename mismatch for Job {job_id}: Token expects '{token_file_name}', received '{fileName}'"
            )
            raise HTTPException(
                status_code=400,
                detail=f"Filename mismatch: Token expects '{token_file_name}', received '{fileName}'",
            )

        # 3) Base64 ë°ì´í„° ë””ì½”ë”©
        base64_str = base64Chunk # ğŸš¨ ìˆ˜ì •: Formìœ¼ë¡œ ë°›ì€ ë¬¸ìì—´ ë³€ìˆ˜ë¥¼ ì‚¬ìš©
        try:
            if not base64_str.strip():
                raise ValueError("empty base64 payload")
                
            # ê°•ë ¥í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ì½”ë”©
            chunk_binary_data = _b64_any_decode(base64_str)
        except Exception as e:
            logger.error(f"Base64 decoding failed for chunk {chunkIndex} (Job {job_id}): {e}")
            raise HTTPException(status_code=400, detail="Invalid Base64 data received in chunk.")

        if not chunk_binary_data:
            logger.error(f"Decoded chunk is empty for chunk {chunkIndex} (Job {job_id})")
            raise HTTPException(status_code=400, detail="Decoded chunk is empty.")

        # 4) ì²­í¬ ì €ì¥ ê²½ë¡œ ì„¤ì •
        chunk_dir = Path(settings.TEMP_ROOT) / job_id
        chunk_dir.mkdir(parents=True, exist_ok=True)

        chunk_filename = f"{job_id}_{token_file_name}.{chunkIndex:04d}"
        chunk_path = chunk_dir / chunk_filename

        # 5) ë””ì½”ë”©ëœ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì“°ê¸°
        with chunk_path.open("wb") as buffer:
            buffer.write(chunk_binary_data)

        logger.info(
            f"Chunk {chunkIndex}/{totalParts} saved for Job {job_id} "
            f"(size={len(chunk_binary_data)}B, path={chunk_path})"
        )
        return {"message": "Chunk uploaded successfully", "jobId": job_id, "chunkIndex": chunkIndex}

    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"Unexpected Error during chunk upload: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error during upload")

@router.post("/complete")
async def complete_presigned_upload(
    # â¬‡â¬‡ ê¸°ë³¸ê°’ ì—†ëŠ” íŒŒë¼ë¯¸í„° ë¨¼ì €
    crypto: CryptoDep,
    background_tasks: BackgroundTasks,

    # â¬‡â¬‡ ê¸°ë³¸ê°’ ìˆëŠ” Form íŒŒë¼ë¯¸í„°ë“¤
    totalParts: int = Form(..., ge=1, description="ì „ì²´ ì²­í¬ ê°œìˆ˜"),
    presignedToken: str = Form(..., description="AES-GCM ë³µí˜¸í™” ê°€ëŠ¥í•œ í† í°"),
):
    """
    ì²­í¬ ì™„ë£Œ í™•ì¸ â†’ ë³‘í•© â†’ AI ì²˜ë¦¬ íŠ¸ë¦¬ê±° (Placeholder ìœ ì§€)
    """
    job_id: str | None = None
    chunk_dir: Path | None = None # Path íƒ€ì… íŒíŠ¸
    try:
        # 1) í† í° ë³µí˜¸í™”/ê²€ì¦
        try:
            token_data: DecryptedToken = crypto.decrypt_token(presignedToken)
            job_id = token_data.jobId
            file_name = token_data.fileName
        except ValueError as e:
            logger.error(f"Token validation failed in /complete: {e}")
            raise HTTPException(status_code=401, detail=f"Invalid or expired token: {str(e)}")

        # 2) ì„ì‹œ ì²­í¬ í´ë” í™•ì¸
        chunk_dir = Path(settings.TEMP_ROOT) / job_id
        if not chunk_dir.exists():
            raise HTTPException(status_code=404, detail="Job ID not found or no chunks uploaded.")

        # 3) ê°œìˆ˜ ê²€ì¦
        chunk_files = sorted(chunk_dir.glob(f"{job_id}_{file_name}.*"))
        actual_parts = len(chunk_files)
        if actual_parts != totalParts:
            logger.error(
                f"Integrity check failed for Job {job_id}: Expected {totalParts} parts, found {actual_parts}."
            )
            shutil.rmtree(chunk_dir, ignore_errors=True)
            raise HTTPException(
                status_code=400,
                detail=f"Incomplete upload: Expected {totalParts} chunks, but only {actual_parts} were received.",
            )

        # 4) ë³‘í•© (ìµœì¢… ì €ì¥ ë£¨íŠ¸: SAVE_ROOT)
        final_path = Path(settings.SAVE_ROOT) / f"{job_id}_{file_name}"
        final_path.parent.mkdir(parents=True, exist_ok=True)

        with final_path.open("wb") as outfile:
            for chunk_file in chunk_files:
                with chunk_file.open("rb") as infile:
                    shutil.copyfileobj(infile, outfile)

        logger.info(f"File merged successfully: {final_path}")

        # 5) ì„ì‹œ ì²­í¬ í´ë” ì •ë¦¬
        shutil.rmtree(chunk_dir, ignore_errors=True)

        # 6) AI ë°ëª¨ ë¹„ë™ê¸° ì‹œì‘ (Placeholder ìœ ì§€)
        background_tasks.add_task(trigger_ai_demo, job_id, final_path)
        logger.info("AI processing successfully initiated (via background task).")

        return {"message": "Upload complete, file merged, and AI processing initiated", "jobId": job_id}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error during completion: {e}")
        # chunk_dirì´ ì •ì˜ë˜ì—ˆê³  ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ì •ë¦¬ ì‹œë„
        if 'chunk_dir' in locals() and chunk_dir and chunk_dir.exists():
             shutil.rmtree(chunk_dir, ignore_errors=True)
        raise HTTPException(status_code=500, detail="Internal server error during file merge")